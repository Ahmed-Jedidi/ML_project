{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chargement du modèle KNN existant...\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import pickle\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import os\n",
    "from fer import FER\n",
    "\n",
    "# Path to save model\n",
    "model_path = 'data/knn_model.pkl'\n",
    "\n",
    "# Load the data X_train\n",
    "with open('data/faces.pkl', 'rb') as w:\n",
    "    faces = pickle.load(w)\n",
    "\n",
    "# Load the data y_train\n",
    "with open('data/names.pkl', 'rb') as f:\n",
    "    labels = pickle.load(f)\n",
    "\n",
    "facec = cv2.CascadeClassifier('data/haarcascade_frontalface_default.xml')\n",
    "\n",
    "# Jedidi Initialize emotion detector from FER\n",
    "emotion_detector = FER()\n",
    "\n",
    "# Vérifiez si le modèle KNN existe déjà\n",
    "if os.path.exists(model_path):\n",
    "    print(\"Chargement du modèle KNN existant...\")\n",
    "    with open(model_path, 'rb') as f:\n",
    "        knn = pickle.load(f)\n",
    "else:\n",
    "    # shape of faces data/matrix\n",
    "    print('Shape of Faces matrix --> ', faces.shape)\n",
    "    print(\"Entraînement d'un nouveau modèle KNN...\")\n",
    "\n",
    "    knn = KNeighborsClassifier(n_neighbors=5)\n",
    "    knn.fit(faces,labels)\n",
    "    \n",
    "    # Sauvegarder le modèle pour une utilisation future\n",
    "    with open(model_path, 'wb') as f:\n",
    "        pickle.dump(knn, f)\n",
    "    print(\"Modèle KNN sauvegardé.\")\n",
    "\n",
    "# Define KNN functions\n",
    "\n",
    "\n",
    "# def distance(x1, x2):\n",
    "#     d = np.sqrt(((x1 - x2) ** 2).sum())\n",
    "#     return d\n",
    "\n",
    "\n",
    "# def knn(xt, X_train=faces, y_train=labels, k=5):\n",
    "#     vals = []\n",
    "\n",
    "#     for ix in range(len(labels)):\n",
    "#         d = distance(X_train[ix], xt)\n",
    "#         vals.append([d, y_train[ix]])\n",
    "\n",
    "#     sorted_labels = sorted(vals, key=lambda z: z[0])\n",
    "#     neighbours = np.asarray(sorted_labels)[:k, -1]\n",
    "\n",
    "#     freq = np.unique(neighbours, return_counts=True)\n",
    "\n",
    "#     # freq[0] is list of names and freq[1] is list of counts\n",
    "#     return freq[0][freq[1].argmax()]\n",
    "\n",
    "# 0 for default camera\n",
    "cam = cv2.VideoCapture(0)\n",
    "\n",
    "#1 for external camera\n",
    "# cam = cv2.VideoCapture(1)\n",
    "\n",
    "while True:\n",
    "    # Capture frame-by-frame (ret = True if frame is available)\n",
    "    # Read the current frame from the webcam\n",
    "    ret, frame = cam.read()\n",
    "    if ret == True:\n",
    "        # Our operations on the frame come here\n",
    "        # Convert the frame to grayscale\n",
    "        # Convert the image from BGR to grayscale because Haar Cascades detect faces in grayscale images efficiently\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "         # Detect faces in the current frame\n",
    "        # scaleFactor: Parameter specifying how much the image size is reduced at each image scale.\n",
    "        # minNeighbors: Parameter specifying how many neighbors each candidate rectangle should have to retain it.\n",
    "        # minSize: Minimum possible object size. Objects smaller than that are ignored.\n",
    "        # maxSize: Maximum possible object size. Objects larger than that are ignored.\n",
    "        # Returns a list of rectangles where each rectangle contains the detected object\n",
    "        # The rectangles are returned as a list of 4-tuples (x, y, w, h)\n",
    "        # x, y are the coordinates of the top-left corner of the rectangle\n",
    "        # w, h are the width and height of the rectangle\n",
    "        # The detected faces are returned as a list of rectangles\n",
    "        face_coordinates = facec.detectMultiScale(gray, 1.3, 5)\n",
    "\n",
    "         # Draw a rectangle around the face using the coordinates returned by detectMultiScale\n",
    "        # The rectangle is drawn on the original image (frame)\n",
    "        for (x, y, w, h) in face_coordinates:\n",
    "            fc = frame[y:y + h, x:x + w, :]\n",
    "            r = cv2.resize(fc, (50, 50)).flatten().reshape(1,-1)\n",
    "            text = knn.predict(r)\n",
    "\n",
    "            # Jedidi Detect emotions in the current frame\n",
    "            emotions = emotion_detector.detect_emotions(frame)\n",
    "\n",
    "            if emotions:\n",
    "                # Jedidi Get the first detected face's emotions\n",
    "                emotion_data = emotions[0]['emotions']\n",
    "                max_emotion = max(emotion_data, key=emotion_data.get)\n",
    "                (ex, ey, ew, eh) = emotions[0][\"box\"]\n",
    "\n",
    "\n",
    "                #cv2.putText(frame, text[0], (x, y-15), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 0), 2)\n",
    "\n",
    "                # Jedidi Display emotion and name on the frame\n",
    "                cv2.putText(frame, f\"{text[0]} - {max_emotion}\", (x, y - 15), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 0), 2)\n",
    "\n",
    "                #drawing a rectangle around the face for showing\n",
    "                # represents the top left corner of rectangle\n",
    "                start_point = (x, y)\n",
    "\n",
    "                # represents the bottom right corner of rectangle\n",
    "                end_point = (x + w, y + h)\n",
    "\n",
    "                # Red color in BGR\n",
    "                color = (0, 0, 255)\n",
    "\n",
    "                # Line thickness of 2 px\n",
    "                thickness = 2\n",
    "                cv2.rectangle(frame, start_point, end_point, (0, 0, 255), thickness)\n",
    "\n",
    "        cv2.imshow('Projet face recogonition Ahmed Jedidi 2eme Ingenieurie', frame)\n",
    "        #ESC key to stop\n",
    "        if cv2.waitKey(1) == 27:\n",
    "            break\n",
    "    else:\n",
    "        print(\"error de lecture de la caméra.\")\n",
    "        break\n",
    "\n",
    "cv2.destroyAllWindows()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
